{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total # of true tensors: {}, true images size: {} 100 torch.Size([3, 32, 32])\n",
      "Total # of fake tensors: {}, fake images size: {} 170 torch.Size([1, 32, 32])\n",
      "True Var Size torch.Size([3, 32, 32])\n",
      "Fake Var Size torch.Size([1, 32, 32])\n",
      "labels:  Variable containing:\n",
      " 0\n",
      " 1\n",
      "[torch.LongTensor of size 2]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#a good example is provided here\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "from PIL import Image\n",
    "from os import listdir\n",
    "import json\n",
    "import numpy as np\n",
    "from random import shuffle\n",
    "\n",
    "# globals \n",
    "disp = False\n",
    "\n",
    "def loadImages(path):\n",
    "    # return array of images\n",
    "\n",
    "    imagesList = listdir(path)\n",
    "    loadedImages = []\n",
    "    for image in imagesList:\n",
    "        img = Image.open(path + image)\n",
    "        loadedImages.append(img)\n",
    "\n",
    "    return loadedImages\n",
    "\n",
    "#define prepro transform\n",
    "'''\n",
    "from:\n",
    "https://github.com/pytorch/examples/blob/409a7262dcfa7906a92aeac25ee7d413baa88b67/imagenet/main.py#L108-L113\n",
    "https://github.com/pytorch/examples/blob/409a7262dcfa7906a92aeac25ee7d413baa88b67/imagenet/main.py#L94-L95\n",
    "'''\n",
    "normalize = transforms.Normalize(\n",
    "   mean=[0.485, 0.456, 0.406],\n",
    "   std=[0.229, 0.224, 0.225]\n",
    ")\n",
    "preprocess = transforms.Compose([\n",
    "   transforms.Scale(40),    \n",
    "   transforms.RandomHorizontalFlip(),   \n",
    "   transforms.RandomCrop(32),\n",
    "   transforms.ToTensor(),\n",
    "   normalize\n",
    "])\n",
    "\n",
    "#provide path to true and fake images\n",
    "true_path= \"raw/person-1/\"\n",
    "fake_path= \"raw/person-2/\"\n",
    "\n",
    "# load images in the dir\n",
    "true_images = loadImages(true_path)\n",
    "fake_images = loadImages(fake_path)\n",
    "\n",
    "#be sure the images are rightly loaded\n",
    "if disp:\n",
    "    true_images[0].show()\n",
    "    fake_images[0].show()\n",
    "\n",
    "# Now preprocess the image\n",
    "\n",
    "#define tensors to hold the images in memory\n",
    "fake_tensors, true_tensors = [], []\n",
    "\n",
    "for imgs in true_images:\n",
    "    true_temp = preprocess(imgs)\n",
    "    true_tensors.append(true_temp)\n",
    "\n",
    "for imgs in fake_images:\n",
    "    fake_temp = preprocess(imgs)\n",
    "    fake_tensors.append(fake_temp)\n",
    "\n",
    "#shuffle the images\n",
    "shuffle(true_images)\n",
    "shuffle(fake_images)\n",
    "\n",
    "# fakenreal_tensors = fake_tensors + true_tensors\n",
    "# print(fakenreal_tensors[240])\n",
    " \n",
    "# #be sure the images are properly loaded in memory\n",
    "print(\"Total # of true tensors: {}, true images size: {}\", len(true_tensors),  true_tensors[0].size())\n",
    "print(\"Total # of fake tensors: {}, fake images size: {}\", len(fake_tensors), fake_tensors[0].size())\n",
    "print(\"True Var Size {}\".format(true_tensors[0].size()))\n",
    "print(\"Fake Var Size {}\".format(fake_tensors[0].size()))\n",
    "\n",
    "# #load labels file\n",
    "# labels_file = open('labels.json').read()\n",
    "# labels = np.fromiter(json.loads(labels_file),int)\n",
    "\n",
    "# #take labels to tensor\n",
    "# labels = torch.from_numpy(labels)\n",
    "# labels = Variable(labels)\n",
    "\n",
    "# print('labels: ', labels)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_X and train_Y sizes: torch.Size([80, 3, 32, 32]) | torch.Size([80])\n",
      "test_X and test_Y sizes: torch.Size([20, 3, 32, 32]) | torch.Size([20])\n"
     ]
    }
   ],
   "source": [
    "#Now separate true and fake to training and testing sets\n",
    "#we'll do 80:20 ratio\n",
    "X_tr = int(0.8*len(true_tensors))\n",
    "X_te = len(true_tensors) - X_tr\n",
    "\n",
    "# allocate tensors memory\n",
    "train_X = torch.LongTensor(X_tr, true_tensors[0].size(0), true_tensors[0].size(1),\n",
    "                          true_tensors[0].size(2))\n",
    "test_X = torch.LongTensor(X_te, true_tensors[0].size(0), true_tensors[0].size(1),\n",
    "                          true_tensors[0].size(2))\n",
    "\n",
    "#Now copy tensors over \n",
    "train_X = torch.stack(true_tensors[:X_tr], 0)\n",
    "train_Y = torch.from_numpy(np.array([1] * train_X.size(0)))\n",
    "\n",
    "#testing set\n",
    "test_X = torch.stack(true_tensors[(X_tr):], 0)\n",
    "test_Y = torch.from_numpy(np.array([1]*X_te))\n",
    "                                      \n",
    "#check size of slices\n",
    "print('train_X and train_Y sizes: {} | {}'.format(train_X.size(), train_Y.size()))\n",
    "print('test_X and test_Y sizes: {} | {}'.format(test_X.size(), test_Y.size()))\n",
    "# print(train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 3x3 Convolution\n",
    "def conv3x3(in_channels, out_channels, stride=1):\n",
    "    return nn.Conv2d(in_channels, out_channels, kernel_size=3, \n",
    "                     stride=stride, padding=1, bias=False)\n",
    "\n",
    "# Residual Block\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1, downsample=None):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.conv1 = conv3x3(in_channels, out_channels, stride)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(out_channels, out_channels)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.downsample = downsample\n",
    "        \n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        if self.downsample:\n",
    "            residual = self.downsample(x)\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "# ResNet Module\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, layers, num_classes=2):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_channels = 16\n",
    "        self.conv = conv3x3(3, 16)\n",
    "        self.bn = nn.BatchNorm2d(16)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.layer1 = self.make_layer(block, 16, layers[0])\n",
    "        self.layer2 = self.make_layer(block, 32, layers[0], 2)\n",
    "        self.layer3 = self.make_layer(block, 64, layers[1], 2)\n",
    "        self.avg_pool = nn.AvgPool2d(8)\n",
    "        self.fc = nn.Linear(64, num_classes)\n",
    "        \n",
    "    def make_layer(self, block, out_channels, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if (stride != 1) or (self.in_channels != out_channels):\n",
    "            downsample = nn.Sequential(\n",
    "                conv3x3(self.in_channels, out_channels, stride=stride),\n",
    "                nn.BatchNorm2d(out_channels))\n",
    "        layers = []\n",
    "        layers.append(block(self.in_channels, out_channels, stride, downsample))\n",
    "        self.in_channels = out_channels\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(out_channels, out_channels))\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.conv(x)\n",
    "        out = self.bn(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.avg_pool(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "resnet = ResNet(ResidualBlock, [3, 3, 3])\n",
    "resnet.cuda()\n",
    "\n",
    "# Loss and Optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "lr = 0.001\n",
    "num_iter = 10\n",
    "optimizer = torch.optim.Adam(resnet.parameters(), lr=lr)\n",
    "\n",
    "# Training \n",
    "for iter in range(num_iter):\n",
    "    images = Variable(train_X.cuda())\n",
    "    labels = Variable(train_Y.cuda())\n",
    "    \n",
    "    print(type(labels.data))\n",
    "        \n",
    "    # Forward + Backward + Optimize\n",
    "    optimizer.zero_grad()\n",
    "    outputs = resnet(images)\n",
    "    print(outputs.size(), labels.size())\n",
    "    loss = criterion(outputs, labels)\n",
    "    print('loss: ', loss)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if (iter+1) % 10 == 0:\n",
    "        print (\"Iter [%d/%d] Loss: %.4f\" %(iter+1, 500, loss.data[0]))\n",
    "\n",
    "    # Decaying Learning Rate\n",
    "    if (iter+1) % 20 == 0:\n",
    "        lr /= 3\n",
    "        optimizer = torch.optim.Adam(resnet.parameters(), lr=lr) \n",
    "        \n",
    "# Test\n",
    "correct = 0\n",
    "total = 0\n",
    "for images, labels in test_loader:\n",
    "    images = Variable(images.cuda())\n",
    "    outputs = resnet(images)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted.cpu() == labels).sum()\n",
    "\n",
    "print('Accuracy of the model on the test images: %d %%' % (100 * correct / total))\n",
    "\n",
    "# Save the Model\n",
    "torch.save(resnet.state_dict(), 'resnet.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
